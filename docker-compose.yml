version: '3.8'

services:
  ########################################
  # 1) ELK Stack for Audit‐Log Ingestion #
  ########################################

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.14
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"

  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.14
    container_name: logstash
    depends_on:
      - elasticsearch
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
      - ./logstash.yml:/usr/share/logstash/config/logstash.yml:ro
    ports:
      - "5001:5001"  # host 5001 → container 5001
    environment:
      - xpack.security.enabled=false
      - LS_JAVA_OPTS=-Xms512m -Xmx512m
    deploy:
      resources:
        limits:
          cpus: "0.5"    # max half a CPU
  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.14
    container_name: kibana
    depends_on:
      - elasticsearch
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"


  ########################################
  # 2) Airflow Metadata Database (Postgres) #
  ########################################

  postgres:
    image: postgres:13
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    volumes:
      - pgdata:/var/lib/postgresql/data


  ########################################
  # 3) Airflow (Scheduler + Webserver)   #
  ########################################

  airflow:
    image: apache/airflow:2.6.3-python3.9
    container_name: airflow
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      # Disable UI authentication (for a local demo only)
      AIRFLOW__WEBSERVER__AUTHENTICATE: 'False'
      # Use LocalExecutor and point at our Postgres for metadata
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW_CONN_POSTGRES_DEFAULT: >
       postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags:ro
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    command: >
      bash -c "
        # Initialize the DB if needed
        airflow db init &&
        # Start the scheduler in the background
        airflow scheduler & 
        # Run the webserver in the foreground
        exec airflow webserver
      "
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 10s
      retries: 5

volumes:
  pgdata:
